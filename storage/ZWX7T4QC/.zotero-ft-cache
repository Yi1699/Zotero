IEEE GEOSCIENCE AND REMOTE SENSING LETTERS, VOL. 19, 2022 4504105
Satellite Image Compression and Denoising With
Neural Networks
Vinicius Alves de Oliveira , Marie Chabert , Member, IEEE, Thomas Oberlin, Charly Poulliat , Member, IEEE,
Mickael Bruno , Christophe Latry, Mikael Carlavan, Simon Henrot, Frederic Falzon, and Roberto Camarero
Abstract— Earth observation through satellite images is crucial to help economic activities as well as to monitor the impact of human activities on ecosystems. Current satellite systems are subjected to strong computational complexity constraints. Thus, image compression is performed onboard with specifically tailored algorithms while image denoising is performed on the ground. In this letter, we intend to address satellite image compression and denoising with neural networks. The first proposed approach uses a single neural architecture for joint onboard compression and denoising. The second proposed approach sequentially uses a first neural architecture for onboard compression and a second one for on ground denoising. For both approaches, the onboard architectures are lightened as much as possible, following the procedure proposed by Alves de Oliveira et al. (2021). The two approaches are shown to outperform the current satellite imaging system and their respective pros and cons are discussed.
Index Terms— Data compression, image denoising, neural networks.
I. INTRODUCTION
R
EMOTE sensing data provide essential information that helps in various applications, such as meteorology, oceanography, geology, natural disaster management, biodiversity conservation, cartography, and military surveillance [2]. The instruments embedded onboard new-generation satellites enable the acquisition of images with ever-increasing spectral and spatial resolutions. The counterparty is an increasing amount of data to be processed onboard and transmitted to the ground. Image compression is thus essential to maximize the scientific return and to reduce transmission time [3]. The currently embedded compression algorithms, such as the Consultative Committee for Space Data Systems (CCSDS)
Manuscript received August 2, 2021; revised November 30, 2021; accepted January 20, 2022. Date of publication January 25, 2022; date of current version February 9, 2022. This work was supported in part by the French Space Agency (CNES), in part by Thales Alenia Space, and in part by the Institute for Artificial and Natural Intelligence Toulouse (ANITI) under Agreement ANR-19-PI3A-0004. (Corresponding author: Vinicius Alves de Oliveira.)
Vinicius Alves de Oliveira is with IRIT/INP-ENSEEIHT, University of Toulouse, 31071 Toulouse, France, and also with the Telecommunications for Space and Aeronautics (TéSA) Laboratory, 31500 Toulouse, France (e-mail: vinicius.oliveira@irit.fr). Marie Chabert and Charly Poulliat are with IRIT/INP-ENSEEIHT, University of Toulouse, 31071 Toulouse, France. Thomas Oberlin is with ISAE-SUPAERO, University of Toulouse, 31055 Toulouse, France. Mickael Bruno and Christophe Latry are with CNES, 31400 Toulouse, France. Mikael Carlavan, Simon Henrot, and Frederic Falzon are with Thales Alenia Space, 06150 Cannes, France. Roberto Camarero is with ESA, 2201 Noordwijk, The Netherlands. Digital Object Identifier 10.1109/LGRS.2022.3145992
compression standard 122.0-B-2 [4], has been designed to reach a compromise between performance and computational complexity, due to strong onboard constraints. The acquired images are affected by an instrumental noise, with well-known statistics and particularly a pixel-dependent variance [5]. Thus, the French Space Agency (CNES) developed a variant of the CCSDS standard 122.0-B-2 [4] that avoids coding the noise by performing a low-complexity onboard hard-denoising. Moreover, onboard compression introduces artifacts modeled as a structured colored noise [6]. Consequently, denoising becomes necessary to recover a noise-free image from the noisy uncompressed image. Currently, denoising is carried out on the ground due to its prohibitive complexity [7]. Denoising is one of the oldest problems in image processing, for which numerous highly efficient model-based algorithms have been proposed. Among them, nonlocal filters are particularly efficient because they exploit the similarities in textures or structures that can be located in distant patches. The nonlocal Bayes (NL-Bayes) algorithm [8] improves the nonlocal filter techniques by performing Bayesian estimation through the estimation of the covariance matrices of the patches. The NL-Bayes is adopted in the satellite imaging system [7] due to its parameter setting simplicity, its high performance and relatively high computation efficiency. Although the model-based image denoising algorithms have demonstrated excellent performance, they present two main disadvantages: they require the manual setting of multiple parameters and they are designed for standard additive noise models. However, the instrumental noise that affects satellite images during acquisition is a nonstandard semimultiplicative noise. Thus, in the CNES current satellite imaging system, a variance stabilizing transform (VST) [9] is used before the denoising algorithm that assumes noise additivity. Note that compression noise is also nonstandard. Compression artifacts removal thus requires some preprocessing such as dequantization [10], [11] or, in the CNES satellite imaging system, an instrumental noise restitution that restores its statistics modified by compression [7]. Notably, convolutional neural networks (CNNs) have been successful in many computer vision applications [12] such as classification [13], object detection [14], [15], segmentation [16], lossy image compression [17], [18], denoising [19], and compression artifacts removal [20]. Recently, end-toend CNNs [17], [18] were shown to outperform traditional compression schemes regarding the rate-distortion tradeoff, however, at the cost of high computational complexity. Based
1558-0571 © 2022 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: Xian Jiaotong University. Downloaded on November 29,2024 at 09:05:17 UTC from IEEE Xplore. Restrictions apply.


4504105 IEEE GEOSCIENCE AND REMOTE SENSING LETTERS, VOL. 19, 2022
Fig. 1. Architecture of the variational autoencoder [18].
on the model proposed in [18], we presented in our previous paper [1] a satellite image compression variant with reduced complexity and competitive performance. Furthermore, denoising CNNs can adapt to any nonstandard noise statistical model as soon as it can be learned from a representative training dataset. In this work, we take advantage of CNNs to address satellite image compression and denoising. We aim to outperform the current satellite imaging system [7] both in compression and denoising without manual parameter setting, without a priori knowledge on the noise statistical model and without tricky procedures (like VST or instrumental noise restitution) to fit the noise to a given model. Besides, we aim to propose possible onboard denoising whereas it is currently mainly performed on ground as a post-processing. We first propose an onboard joint compression and denoising approach with a single neural architecture based on [18]. Second, we propose a modular neural architecture, that performs sequentially onboard compression based on [18] and on ground denoising based on [21]. This sequential approach allows to lighten the onboard computational load if required, especially since it is compatible with every complexity reduction proposed in [1]. This letter addresses a hot topic since neural networks are likely to run onboard the next generation imaging satellites. The remaining of the letter is organized as follows. Section II recalls the background regarding compression and denoising with neural networks. Section III details the proposed joint and sequential approaches. Section IV, devoted to the experiments, compares the performance of both approaches to that of the CNES satellite pipeline. Section V concludes the letter.
II. BACKGROUND
A. Compression With Neural Networks
When devoted to lossy image compression, autoencoders learn a representation with low entropy after quantization [17], [18]. In this work, we focus on the reference architecture [18] displayed on Fig. 1. It is composed of a main autoencoder and a side autoencoder described below. In the main autoencoder [see Fig. 1 (left)], an analysis transform (Ga) is applied to the input image I to produce a learned representation y = Ga(I). Then y is quantized at the bottleneck, for further entropy coding, leading to the quantized representation ˆy. Afterward, the synthesis transform (Gs) is applied to the ˆy to reconstruct the input image ˆI = Gs(ˆy). The analysis and synthesis transforms are performed through
multiple convolutional layers composed of filters followed by nonlinear activation functions. N denotes the number of filters in each layer, except in the last layer before the bottleneck composed by M filters. Indeed, the so-called wide bottleneck strategy advocates M > N [18]. Activation functions called generalized divisive normalizations (GDNs) [resp. inverse GDN (IGDN)] allow one to implement a local adaptive normalization. The learned representation is multichannel and nonlinear. The autoencoder parameters (the filter weights and the GDN/IGDN parameters) as well as the probability distribution of the learned representation, the so-called entropy model pˆy(ˆy) (required for coding purpose), are jointly learned through the minimization of a loss function that establishes a tradeoff between the rate R(yˆ ) and the distortion D(I, ˆI) between the original image I and the reconstructed image ˆI. ˆy can be losslessly compressed using entropy coding algorithms, such as arithmetic coding [22]. The rate accounts for the expected code length of the compressed representation. The distortion measure D stands for the image quality and usually defaults to the mean square error (mse). The rate-distortion criterion then writes as the weighted sum
J = λD(I, Iˆ) + R(yˆ) (1)
where parameter λ tunes the rate-distortion tradeoff. This loss function is minimized through gradient descent with backpropagation [12] on a representative image training set. The bit rate is minimized if pˆy(ˆy) is equal to the actual distribution of the learned image representation. The side autoencoder [see Fig. 1 (right)] estimates the hyper-parameters of the image representation distribution [18]. This estimation is performed individually for each image, during the learning process, and during the operational phase. This model takes into account possible spatial dependency in each input image representation. We have shown, in the specific case of satellite images, that the representation coefficients can be beneficially modeled as uncorrelated Laplacian variables [1]. Then, the computationally expensive side autoencoder [18] has been substituted with the simple estimation of the Laplace distribution scale parameter in [1].
B. Denoising With Neural Networks
CNNs have also shown high performance in image denoising. Denoising CNN (DnCNN) adopted residual learning (RL) and batch normalization (BN) to improve the denoising performance [19]. RL estimates the noise, which is expected to be easier to learn than the denoised image [23]. BN facilitates training convergence [24]. The more recent batch-renormalization denoising network (BRDNet) [25] adopted RL similar to [19], batch renormalization (BRN) [26] to deal with small mini-batch convergence issues and dilated convolutions to afford lower complexity [27]. Indeed, networks involving dilated convolution attain the same receptive field as those involving conventional ones, with fewer layers and thus fewer parameters. BRDNet combines two sub-networks in parallel for improved denoising performance [21] (see Fig. 2). BRDNet outperforms state-of-the-art denoising architectures [25], e.g., DnCNN [19], but also the fast and flexible
Authorized licensed use limited to: Xian Jiaotong University. Downloaded on November 29,2024 at 09:05:17 UTC from IEEE Xplore. Restrictions apply.


ALVES DE OLIVEIRA et al.: SATELLITE IMAGE COMPRESSION AND DENOISING WITH NEURAL NETWORKS 4504105
Fig. 2. Architecture of the BRDNet [25].
denoising network (FFDNet) [28] and the image-restoration CNN (IRCNN) [29]. At the end of the day, denoisingdedicated architectures involves RL, BN, or BRN and are significantly deep. The architectures dedicated to compression artifacts removal [20] are quite similar, and, in particular, involve RL. However, the compression-dedicated architectures are significantly different: they do not involve RL nor BN and are relatively shallow [17], [18]. This exemplifies the difficulty of conceiving a unique architecture that jointly performs compression and denoising.
III. COMBINING COMPRESSION AND DENOISING
Currently, as recalled in Section I, the compression is performed onboard the satellite whereas the denoising is performed on ground, because of its prohibitive computational cost [7]. However, the evolution of satellite computing capacities enables onboard denoising to be reasonably envisioned [7]. This work adopts data-driven approaches for satellite image compression and denoising, possibly both performed onboard. The aim is to attain high performance while dispensing with manual parameter setting, with a priori knowledge of the noise model or with tricky intermediary steps (like VST or instrumental noise restitution). The first proposed approach takes advantage of the compressiondedicated architecture, proposed in [18] and adapted to satellite in [1], to jointly perform compression and denoising onboard. The second proposed approach sequentially combines a compression-dedicated architecture and a denoisingdedicated one. Thanks to its modular structure, this sequential approach allows to choose the best architectures for compression [18] and for denoising [25], respectively. Moreover, this approach facilitates consideration of the onboard hardware constraints since all the complexity-reductions proposed in [1] can be applied to the compression-dedicated architecture in this case. The question of computational complexity is less crucial for the on ground denoising-dedicated architecture. Finally, note that whether the joint or the sequential approach are expected to suppress compression artifacts together with instrumental noise [7]. In the following, In denotes the noisy image produced by the acquisition device. Indeed, the instrumental noise is dependent on the ideal noise-free image, denoted as Inf . The transmission is assumed not to introduce additional degradations [30]. Realistic simulation of satellite images provide both In and Inf for the same scene, which makes architecture training and validation possible. Note that simulation is commonly used in remote sensing image neural processing, in particular, due to the lack of raw data [31].
A. Joint Compression and Denoising
The joint compression and denoising approach, denoted as CD-H in the following, exploits the compression-dedicated architecture displayed in Fig. 1 [18], with the number of filters reduction proposed in [1]. The input is the noisy acquired image (In). In order to jointly perform denoising and compression, the architecture parameters are learned through the optimization of a specific loss function (different from the one used in [18] and [1]): the rate R(yˆ ) is the same but the distortion D(Inf , Gs [Ga(In)]) now measures the similarity between the reconstructed image ˆInf = Gs[Ga(In)] and the reference noise-free image Inf (instead of the input image). The reconstructed image is thus expected to be denoised.
B. Sequential Compression and Denoising
The sequential compression and denoising approach exploits two architectures: the compression-dedicated one detailed in Section II-A (with two versions denoted, respectively, C-H when featuring the hyperprior [18] and C-L when featuring the Laplacian entropy model [1]), and the denoising-dedicated architecture BRDNet, detailed in Section II-B [25], from which we expect also compression artifact reduction.
C. Denoising as a Post-Processing After Joint Compression and Denoising
Finally, the BRDNet denoising-dedicated architecture was applied on ground to images that have already been jointly compressed and denoised on board. This post-processing aims at removing the remaining noise and the compression artifacts.
IV. EXPERIMENTS
To assess the relevance of the proposed approaches, experiments were reconducted using Tensorflow. The CNES imaging system [7] serves as a baseline for compression and denoising performance.
A. Reference CNES Imaging System
In the CNES imaging system, the acquired noisy image In is compressed onboard the satellite using a customized version [32] of the CCSDS 122.0-B-2 standard [4], denoted as C-CNES in the following. The compressed noisy image is then transmitted to an earth station, decompressed on ground leading to ˆIn and then denoised. After decompression, the instrumental noise, which has been modified by the quantization during compression, is restored [7]. The VST [9] is then applied to the denoised image to transform the signal-dependent noise into an additive one. These operations increase the performance of the subsequent customized NL-Bayes denoising algorithm [5], which strongly depends on the noise model. Finally, the inverse VST is applied [9].
B. Experimental Setup
1) Datasets: Our training (resp. test) dataset is composed of 112 (resp. 16) pairs of noise-free (Inf ) and noisy (In) 12-bit simulated Pléiades panchromatic images (of size 586 × 586)
Authorized licensed use limited to: Xian Jiaotong University. Downloaded on November 29,2024 at 09:05:17 UTC from IEEE Xplore. Restrictions apply.


4504105 IEEE GEOSCIENCE AND REMOTE SENSING LETTERS, VOL. 19, 2022
Fig. 3. Example result on a test image. (a) CNES-C+NL-Bayes [7]. (b) C-H+BRDNet. (c) CD-H. (d) Noise-free image (Inf ).
covering various landscapes, provided by the CNES. The instrumental noise is simulated according to [7]. For learning the proposed compression-dedicated architectures, patches (of size 256 × 256) randomly cropped from the noisy images (In) of the training dataset are put at the network input and serve as a reference for the distortion derivation. For learning the proposed joint compression and denoising architectures, the patches at the input of the network are the same as before whereas homologous patches cropped from the noise-free image Inf serve as the reference for distortion derivation. For learning the denoising-dedicated architectures, that proceed a post-processing after compression (resp. after joint compression and denoising), patches of size 50 × 50, randomly cropped from the noisy uncompressed images ˆIn (resp. denoised uncompressed images ˆInf ) are put at the network input whereas homologous patches cropped from Inf serve as the reference for the distortion derivation. Performance assessment of these three types of architectures uses the same configurations as for their respective learning, however, considering full images of the test dataset, instead of patches. 2) Architecture Dimensioning: For CD-H and C-H, N = 64 and M = 320 for the main and side autoencoders (see Fig. 1) according to the number of filter reduction proposed in [1].The filter kernel size is 5 × 5. C-L uses the same size main auto-encoder but the Laplacian entropy model [1] instead of the side autoencoder. The convolutional layers of the denoising-dedicated architecture are composed of 64 filters with kernel size 3 × 3 [25]. 3) Training Parameters: For learning the compressiondedicated and the joint compression and denoising architectures, the batch size was set to 8 and up to 2 million iterations were performed. For learning the denoising-dedicated architecture, the batch size was set to 20 and up to 500 000 iterations were performed [25]. MSE was used as the distortion metric for training.
C. Performance Analysis
1) In Terms of Subjective Image Quality: Fig. 3 provides an example of the uncompressed and denoised image, obtained with the CNES baseline and with the proposed approaches for similar rates. Even if all the methods perform satisfactorily, the image obtained with the joint compression and denoising approach CD-H is visually the closest to the noise-free reference whereas the sequential approach (C-H followed by BRDNet) tends to produce a slightly smoothed image. Note that the current CNES pipeline also adds noise in areas where intensity is low, as is not the case for the proposed approaches.
Fig. 4. Rate-distortion curves (distortion measured in terms of PSNR (dB) between the output image ˆInf and the noise-free image Inf ).
2) In Terms of Rate Distortion: The joint compression and denoising architecture CD-H, the sequential compression and denoising approach, C-H or C-L followed by BRDNet, and the baseline, C-CNES followed by CNES-customized NLBayes [5], are compared. Fig. 4 shows the rate-distortion performance averaged over the test dataset. The distortion is measured in terms of peak signal-to-noise ratio (PSNR) (dB) between the output image ˆInf and the noise-free image Inf . These experiments show that the proposed joint compression and denoising architecture CD-H outperforms the CNES baseline over the considered bit range between 2 and 3.7 bits/pixel. The advantage of the proposed joint compression and denoising method reduces at higher rates. Note that this architecture was also tested when replacing the hyperprior autoencoder by the simpler uncorrelated Laplacian entropy model proposed in [1], but without success. Indeed, although the learned features are mostly Laplacian distributed, the assumption of spatial independence is no longer valid. Note, however, that the considered CD-H architecture [1] is an already highly simplified architecture with respect to [18]. The sequential compression and denoising approaches (C-H or C-L followed by BRDNet) performs similarly and even better than the joint compression and denoising approach (CD-H), particularly for the highest bit rates. The approach that performs denoising as a post-processing to joint compression and denoising (CD-H followed by BRDNet), performs slightly better for rates between 2.2 and 3.2 bits/pixel. Besides, for this bit rate range, it outperforms all the other approaches whereas it performs similarly as the sequential approaches at high rates. Finally, note that, simply replacing NL-Bayes algorithm by BRDNet architecture on ground, in the CNES satellite imaging system,
Authorized licensed use limited to: Xian Jiaotong University. Downloaded on November 29,2024 at 09:05:17 UTC from IEEE Xplore. Restrictions apply.


ALVES DE OLIVEIRA et al.: SATELLITE IMAGE COMPRESSION AND DENOISING WITH NEURAL NETWORKS 4504105
leads to a gain in performance, without any modification onboard. 3) In Terms of Complexity: The complexity of the onboard embedded architecture, involved in CD-H, C-H, and C-L, has been discussed in detail in [1]. Concerning the denoisingdedicated architecture, we will focus on time complexity. It is indeed the more critical criterion on ground since it determines the pipeline throughput. BRDNet denoises in average 2.192 × 106 pixels/s on an NVIDIA Tesla V100 GPU with 32 GB onboard memory, whereas the reference CNES-customized NL-Bayes denoises on average 0.073 × 106 pixels/s on an Intel i7-6700 HQ (2.6–3.5 GHz) CPU with 8 GB RAM [5]. Finally, BRDNet, benefiting from the GPU massively parallel architecture, denoises approximately 30 times faster than the CNES-customized NL-Bayes.
V. CONCLUSION
This letter proposed different learned approaches for satellite image compression and denoising. On one side, the joint approach performs compression and denoising with a single architecture. One advantage is that intermediary steps existing in the current CNES imaging system [7] can be eliminated. This approach is of interest for commercial applications since it provides noise-free images without on ground postprocessing. On the other side, the sequential approach allows to consider a splitting compatible with all the architecture simplifications designed for onboard compression [1]. The proposed approaches were shown to outperform the CNES baseline in terms of rate distortion, visual quality, and computational time.
REFERENCES
[1] V. Alves de Oliveira et al., “Reduced-complexity end-to-end variational autoencoder for on board satellite image compression,” Remote Sens., vol. 13, no. 3, p. 447, Jan. 2021. [2] G. Yu, T. Vladimirova, and M. N. Sweeting, “Image compression systems on board satellites,” Acta Astronautica, vol. 64, pp. 988–1005, May/Jun. 2009. [3] B. Huang, Satellite Data Compression. New York, NY, USA: Springer, 2011.
[4] Consultative Committee for Space Data Systems (CCSDS), Image Data Compression CCSDS 122.0-B-2, Blue Book, CCSDS Secretariat, Nat. Aeronaut. Space Admin., Washington, DC, USA, Sep. 2017. [5] A. Masse, S. Lefevre, R. Binet, S. Artigues, G. Blanchet, and S. Baillarin, “Denoising very high resolution optical remote sensing images: Application and optimization of nonlocal Bayes method,” IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., vol. 11, no. 3, pp. 691–700, Mar. 2018. [6] C. Latry, S. Fourest, and C. Thiebaut, “Restoration technique for pleiades-HR panchromatic images,” Int. Arch. Photogramm., Remote Sens. Spatial Inf. Sci., vol. 39, pp. 555–560, Jul. 2012. [7] J.-M. Delvit, C. Thiebaut, C. Latry, G. Blanchet, and R. Camarero, “A pipeline to improve compressed image quality,” Proc. SPIE, vol. 11180, Jul. 2019, Art. no. 111807I. [8] M. Lebrun, A. Buades, and J.-M. Morel, “A nonlocal Bayesian image denoising algorithm,” SIAM J. Imag. Sci., vol. 6, no. 3, pp. 1665–1688, Sep. 2013.
[9] F. J. Anscombe, “The transformation of Poisson, binomial and negativebinomial data,” Biometrika, vol. 35, nos. 3–4, pp. 246–254, 1948. [10] A. Foi, V. Katkovnik, and K. Egiazarian, “Pointwise shape-adaptive DCT for high-quality denoising and deblocking of grayscale and color images,” IEEE Trans. Image Process., vol. 16, no. 5, pp. 1395–1411, May 2007. [11] T. Oberlin, F. Malgouyres, and J.-Y. Wu, “Loss functions for denoising compressed images: A comparative study,” in Proc. 27th Eur. Signal Process. Conf. (EUSIPCO), Sep. 2019, pp. 1–5.
[12] Y. Bengio, “Learning deep architectures for AI,” Found. Trends Mach. Learn., vol. 2, no. 1, pp. 1–127, 2009. [13] J. Hu, L. Shen, and G. Sun, “Squeeze-and-excitation networks,” in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., Jun. 2018, pp. 7132–7141. [14] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, “You only look once: Unified, real-time object detection,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2016, pp. 779–788.
[15] Q. He, X. Sun, Z. Yan, and K. Fu, “DABNet: Deformable contextual and boundary-weighted network for cloud detection in remote sensing images,” IEEE Trans. Geosci. Remote Sens., vol. 60, pp. 1–16, 2022. [16] P. Kaiser, J. Wegner, A. Lucchi, M. Jaggi, T. Hofmann, and K. Schindler, “Learning aerial image segmentation from online maps,” IEEE Trans. Geosci. Remote Sens., vol. 55, no. 11, pp. 6054–6068, Nov. 2017. [17] J. Balle, V. Laparra, and E. P. Simoncelli, “End-to-end optimized image compression,” in Proc. Int. Conf. Learn. Represent. (ICLR), Apr. 2017, pp. 1–27. [18] J. Ballé, D. Minnen, S. Singh, S. J. Hwang, and N. Johnston, “Variational image compression with a scale hyperprior,” in Proc. Int. Conf. Learn. Represent. (ICLR), 2018, pp. 1–23.
[19] K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang, “Beyond a Gaussian denoiser: Residual learning of deep CNN for image denoising,” IEEE Trans. Image Process., vol. 26, no. 7, pp. 3142–3155, Jul. 2017. [20] C. Dong, Y. Deng, C. C. Loy, and X. Tang, “Compression artifacts reduction by a deep convolutional network,” in Proc. IEEE Int. Conf. Comput. Vis. (ICCV), Dec. 2015, pp. 576–584. [21] C. Szegedy et al., “Going deeper with convolutions,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2015, pp. 1–9.
[22] J. Rissanen and G. Langdon, “Universal modeling and coding,” IEEE Trans. Inf. Theory, vol. 27, no. 1, pp. 12–23, Jan. 1981. [23] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2016, pp. 770–778. [24] S. Ioffe and C. Szegedy, “Batch normalization: Accelerating deep network training by reducing internal covariate shift,” in Proc. Int. Conf. Mach. Learn. (ICML), 2015, pp. 448–456.
[25] C. Tian, Y. Xu, and W. Zuo, “Image denoising using deep CNN with batch renormalization,” Neural Netw., vol. 121, pp. 461–473, Jan. 2020. [26] S. Ioffe, “Batch renormalization: Towards reducing minibatch dependence in batch-normalized models,” in Proc. Int. Conf. Neural Inf. Process. Syst. (NeurIPS), 2017, pp. 1942–1950.
[27] F. Yu and V. Koltun, “Multi-scale context aggregation by dilated convolutions,” in Proc. ICLR, 2016, pp. 1–13. [28] K. Zhang, W. Zuo, and L. Zhang, “FFDNet: Toward a fast and flexible solution for CNN-based image denoising,” IEEE Trans. Image Process., vol. 27, no. 9, pp. 4608–4622, Sep. 2018. [29] K. Zhang, W. Zuo, S. Gu, and L. Zhang, “Learning deep CNN denoiser prior for image restoration,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jul. 2017, pp. 3929–3938. [30] M. Carlavan, L. Blanc-Féraud, M. Antonini, C. Thiebaut, C. Latry, and Y. Bobichon, “A satellite imaging chain based on the compressed sensing technique,” in Proc. On-Board Payload Data Compress. Conf., 2012. [31] X. Sun, B. Wang, Z. Wang, H. Li, H. Li, and K. Fu, “Research progress on few-shot learning for remote sensing image interpretation,” IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., vol. 14, pp. 2387–2402, 2021. [32] C. Thiebaut et al., “Performances of a CCSDS-based algorithm for quality-controlled compression on earth observation missions,” in Proc. On-Board Payload Data Compress. Conf., 2016.
Authorized licensed use limited to: Xian Jiaotong University. Downloaded on November 29,2024 at 09:05:17 UTC from IEEE Xplore. Restrictions apply.