IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 63, 2025 5603123
Optimizing Satellite Image Analysis: Leveraging
Variational Autoencoders Latent Representations
for Direct Integration
Alessandro Giuliano , Graduate Student Member, IEEE,
S. Andrew Gadsden , Senior Member, IEEE, and John Yawney
Abstract— Variational autoencoders (VAEs) have emerged as powerful tools for data compression and representation learning. In this study, we explore the application of VAE-based neural compression models for compressing satellite images and leveraging the latent space directly for downstream machine learning tasks, such as classification. Traditional approaches to image compression require decoding the compressed format for subsequent analysis. However, we propose that the latent representation constructed by these models can be utilized directly by another machine learning model without explicit reconstruction, or inverse transform. We utilize latent spaces derived from neural compression model-encoded Sentinel-2 images for downstream classification tasks. We demonstrate the viability and flexibility of this approach, showcasing the impact of fine-tuning the neural compression models to further increase classification performance, achieving the same accuracy as state-of-the-art models at lower bitrates. By training these models to compress satellite images into a low-dimensional latent space, we show that the latent representations capture meaningful information about the original images, facilitating accurate classification without the overhead of reconstruction. Our results highlight the potential of neural compression methods for direct satellite image analysis, offering a promising avenue for efficient data transmission and processing in remote sensing applications.
Index Terms— Neural compression, remote sensing, variational autoencoders (VAEs).
I. INTRODUCTION
R
EMOTE sensing plays a critical role in numerous applications such as environmental monitoring, disaster management, and agricultural planning. Satellites like Sentinel-1, 2, 3, and 5 provide high-resolution imagery essential for these tasks. However, the sheer volume of data generated by these satellites presents significant challenges for storage, transmission, and analysis. Traditional image compression techniques aim to reduce data size while preserving visual quality. These methods typically involve quasi-lossless or lossless compression algorithms
Received 25 June 2024; revised 16 September 2024; accepted 7 December 2024. Date of publication 20 December 2024; date of current version 6 January 2025. This work was supported in part by the Natural Sciences and Engineering Research Council of Canada (NSERC), in part by NSERC Discovery under Grant RGPIN-2022-04853, and in part by NSERC Alliance under Grant ALLRP-566259-2021. (Corresponding author: Alessandro Giuliano.)
Alessandro Giuliano and S. Andrew Gadsden are with the Department of Mechanical Engineering, McMaster University, Hamilton, ON L8S 4L8, Canada (e-mail: giuliana@mcmaster.ca; gadsdesa@mcmaster.ca). John Yawney is with Adastra Corporation, Toronto, ON M5J 2J2, Canada (e-mail: john.yawney@adastragrp.com). Digital Object Identifier 10.1109/TGRS.2024.3520879
Fig. 1. General architecture of a VAE.
that require the compressed images to be decompressed before any analysis can be performed. While effective for reducing storage requirements, this two-step process of compression and decompression can be computationally expensive and inefficient, especially when real-time analysis is needed. Compressed data is relayed back to Earth, preprocessed, and analyzed to be used for a wide variety of tasks. In recent years, deep learning-based image analysis has grown in popularity and represents the state-of-the-art for many image analysis tasks [1], including image fusion [2], image registration [3], scene classification [4], object detection [5], land use and land cover (LULC) classification [6], segmentation [7], and object-based image analysis (OBIA) [8]. With the advancement of machine learning new compression methods also emerged. Neural compression techniques, particularly those based on variational autoencoders (VAEs), have shown great promise for compressing complex data while retaining meaningful features in the compressed representation. Neural compression has been shown to outperform conventional compression methods such as joint photographic experts group (JPEG) on a broad scale [9], [10], [11], and specifically in compressing satellite images as well [12]. VAEs, as illustrated in Fig. 1, are generative models that learn to encode input data into a lower dimensional latent space iteratively through composite optimization and then decode it back to the original format. The latent space, a compressed representation of the input data, captures essential information and underlying structures through multiple nonlinear projections. A novel approach to neural compression utilization is to leverage the latent spaces generated by the transformation of the original data directly for downstream tasks, bypassing the need for reconstruction. This can potentially streamline the process, reducing computational overhead and enhancing
1558-0644 © 2024 IEEE. All rights reserved, including rights for text and data mining, and training of artificial intelligence and similar technologies. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


5603123 IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 63, 2025
efficiency. The hypothesis is that the latent representations produced by VAEs are rich enough to serve as inputs for machine learning models, such as classifiers, thereby facilitating direct and effective analysis of compressed data. This study aims to investigate the viability of using neural compression-derived latent spaces specifically for direct classification of Sentinel-2 satellite images. By fine-tuning these models, we seek to understand the impact on the quality of the latent space, classification accuracy, and reconstruction quality performance. The approach is validated through extensive experiments on Sentinel-2 satellite images, demonstrating the validity of the approach and flexibility of using neural compression model-derived latent spaces for downstream machine learning tasks. Demonstrating the effectiveness of this approach could significantly advance the field of remote sensing, offering a more efficient method for handling large-scale satellite imagery. This article makes the following key contributions.
1) The study proposes using the latent representation constructed by neural compression models directly for downstream machine learning tasks, such as classification. Without the need for explicit reconstruction or inverse transform, the learned latent space can be leveraged immediately for downstream tasks like classification, making the process more efficient. The results validate the possibility of using the lower dimensional representation of the data directly in contrast with conventional methods. 2) It demonstrates the viability and flexibility of this approach through experiments with latent spaces derived from neural compression model-encoded Sentinel-2 images, specifically for classification tasks. 3) The impact of fine-tuning state-of-the-art compression models is examined, showing how it can enhance downstream task accuracy while maintaining compression performance. 4) A new metric is introduced for evaluating the ratedistortion-accuracy tradeoff, providing a comprehensive measure that balances compression efficiency, reconstruction quality, and classification performance.
To the best of the authors’ knowledge, this is the first attempt at leveraging neural compression latent spaces for direct use in downstream machine learning tasks. By eliminating the need for explicit decompression, this approach significantly reduces computational overhead, making it possible to develop more efficient and streamlined architectures. Furthermore, by transmitting the latent space representation of the original data, an additional security layer is implemented in terms of masking the original data through nonlinear transforms. Masking the data makes it more difficult for unauthorized parties to reconstruct the original data without access to the specific decoding model or to make use of it without models trained explicitly using clear data. Unlike traditional image compression methods that require full reconstruction for analysis, our approach leverages the latent representations directly for classification tasks. This eliminates the need for the inverse transform, significantly
reducing computational overhead and improving efficiency in real-time applications. The ability to use compressed representations directly could lead to advancements in various fields that rely on large-scale data analysis, such as remote sensing, environmental monitoring, and urban planning. This study sets a precedent for future research to explore and optimize the integration of neural compression models with machine learning frameworks, ultimately aiming to achieve higher performance and greater scalability. The rest of the article is structured as follows. Section II covers conventional data compression methods, neural compression, and how neural compression has been applied to satellite imagery. Section III covers the dataset used, neural compression and classification models, latent space representation techniques, fine-tuning methods, as well as the overall architecture, experimental setup, and evaluation metrics. Section V covers qualitative and quantitative results, a comparison between baseline and fine-tuning, latent space visualizations, and rate-distortion accuracy plots. Section VI covers insights, advantages, limitations, and future work as well as security considerations. Finally, Section VII concludes the article remarking the findings.
II. RELATED WORK
A. Deep Learning in Satellite Image Analysis
The use of deep learning in satellite image analysis has gained significant attention in recent years, driven by the increasing availability of high-resolution satellite imagery and advances in neural network architectures. These techniques have been applied to a wide range of tasks, including land cover classification, object detection, change detection, and image segmentation. Recent advancements in hyperspectral imaging have further highlighted the significance of fusion-aware computational techniques for improving image quality, particularly in complex scenes. For instance, the CasFormer model proposed by Li et al. [13] introduces a novel cascaded transformer architecture that effectively enhances hyperspectral imaging by integrating red, green, and blue (RGB) and spectral data through spatial coherence alignment and spectral recovery. This approach demonstrates state-of-the-art performance by achieving high spatial consistency and spectral fidelity, which is crucial for applications in environmental monitoring, medical diagnosis, and remote sensing. Interpretability and robustness remain critical challenges in hyperspectral anomaly detection, particularly in complex environments. To address these issues, Li et al. [14] introduced a novel paradigm that integrates model-driven low-rank representation (LRR) methods with data-driven deep learning techniques. By leveraging disentangled priors (LDPs), their approach effectively separates explicit from implicit priors, resulting in improved detection accuracy and enhanced generalization across a variety of hyperspectral datasets. This integration of explicit low-rank priors with implicitly learned features represents a significant advancement in hyperspectral anomaly detection. In addition, the authors propose a deep unfolding solution, LRR-Net+, which fuses LRR with deep learning to bolster
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


GIULIANO et al.: OPTIMIZING SATELLITE IMAGE ANALYSIS: VAEs LATENT REPRESENTATIONS 5603123
anomaly detection while maintaining interpretability. This approach bridges the gap between data-driven and modeldriven methods by incorporating the alternating direction method of multipliers (ADMMs) optimizer, which strikes an effective balance between performance and explainability in hyperspectral anomaly detection tasks. The introduction of the AIR-HAD dataset further demonstrates the robustness of this method across diverse scenarios [15]. Addressing the challenges of generalization in remote sensing tasks across different urban environments, Hong et al. [16] introduced the CrossCity multimodal dataset, which facilitates cross-city semantic segmentation through domain adaptation techniques. The authors present the HighDAN network, a highresolution domain adaptation framework that improves the transferability of learned models between cities by minimizing domain shifts. This work is particularly relevant for tasks involving multimodal data integration and has set a new benchmark for semantic segmentation across diverse geographical regions. The emergence of foundation models has also opened new avenues in remote sensing, particularly in spectral data analysis. The SpectralGPT model, introduced by Hong et al. [17], represents a significant advancement by tailoring the generative pretrained transformer (GPT) architecture to spectral remote sensing. This model excels in handling large-scale spectral data through its innovative 3-D masking strategy and multitarget reconstruction, leading to superior performance across various downstream tasks such as classification, segmentation, and change detection. SpectralGPT’s ability to generalize across diverse datasets highlights its potential in advancing remote sensing applications.
B. Conventional Satellite Data Compression Techniques
Traditional methods for satellite data compression have relied heavily on both lossless and lossy compression techniques to reduce the volume of data while attempting to preserve the essential information needed for analysis. These conventional techniques include methods like JPEG, JPEG2000, and other domain-specific algorithms. Lossless compression techniques, such as run-length encoding (RLE) [18], Huffman coding [19], and Lempel–Ziv–Welch (LZW) [20], aim to reduce data size without any loss of information. These methods are particularly valuable in applications where the integrity of the original data must be maintained, such as in scientific and technical imagery analysis. However, the compression ratios achieved by these methods are limited by Shannon’s theoretical lossless compression limit, equivalent to the corresponding entropy of the data being transmitted. Lossy compression techniques, such as JPEG and JPEG2000, provide higher compression ratios by allowing some loss of information [21]. These techniques are designed to exploit the human visual system’s limitations, removing less noticeable details to achieve more significant data reduction. JPEG2000, in particular, has been widely used in satellite image compression due to its ability to offer higher compression ratios and better quality at lower bitrates compared to standard JPEG. Satellites also use several
near-lossless image compression techniques, such as Successive approximation multi-stage vector quantization (SAMVQ) and hierarchical self-organizing cluster vector quantization (HSOCVQ). These methods aim to limit compression errors to levels comparable to the intrinsic noise of the original data, reducing the impact on remote sensing applications [22]. SAMVQ works by organizing 2-D focal plane frames into regional datacubes, which are then split into subsets for parallel processing. Each subset is classified based on spectral similarity, enabling faster processing and better memory use through independent compression. Conversely, HSOCVQ classifies the entire datacube into clusters based on spectral similarity rather than splitting it into smaller sections. This technique enhances compression by grouping similar spectra, and aligning clusters with specific scene targets. Predictive coding methods, such as differential pulse code modulation (DPCM) and the more advanced context-based adaptive binary arithmetic coding (CABAC) used in H.264/advanced video coding (AVC), predict pixel values based on neighboring pixels, encoding only the prediction errors [23]. These methods are effective in reducing redundancy in satellite images, which often contain large areas of homogeneous regions.
C. Neural Compression
Recent advancements in image compression using neural networks have shown significant improvements over traditional methods [9]. Various architectures and techniques have been proposed to address specific challenges in this field. Neural compression employs neural networks and machine learning techniques to optimize data compression processes, specifically in the transform phase. This innovative approach utilizes deep generative models such as VAEs [9], generative adversarial networks (GANs) [24], normalizing flows [25], and autoregressive models [26] to learn compression algorithms directly from data end to end. By capturing complex data distributions, neural compression can significantly enhance the efficiency and effectiveness of data reduction compared to traditional methods such as discrete cosine transform (DCT) used in JPEG coding [21]. Different entropy models, including fully factorized models [10], and hyperprior models [27], have been explored to improve the rate-distortion performance of learned image compression methods. The selection of an appropriate entropy model is essential for optimizing bit-rate and maintaining high-quality reconstructions. The core idea behind neural compression is the replacement of linear transforms with neural network-based nonlinear transforms, enabling more flexible and adaptive data representations. The field has evolved rapidly since the introduction of deep generative models for data compression around 2016, when the parallels between variational inference and both lossless and lossy compression methods came to light. The introduction of hyperprior models [27], discretized Gaussian mixture likelihood models [11], hierarchical structures [28], and more [29], [30], has significantly advanced image compression performance since. These models estimate the likelihoods of the latent representations more accurately by capturing spatial dependencies, thereby enhancing the entropy coding process. The hyperprior approach, originally proposed
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


5603123 IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 63, 2025
Fig. 2. General neural compression model structure.
for natural images, has been adapted and optimized for satellite imagery, showing considerable improvements in compression efficiency [12]. A typical neural compression pipeline involves transforming the input data into a lower dimensional latent space using an encoder, followed by quantization and entropy coding to achieve a compressed representation, as seen in Fig. 2. The decoder then reconstructs the data from this compressed form. This end-to-end learning process optimizes both the bit rate and the distortion, balancing compression efficiency with the quality of the reconstructed data. In addition, advancements in neural compression often integrate perceptual metrics and adversarial losses to enhance the realism and perceptual quality of the reconstructions. Neural compression’s flexibility is particularly beneficial for new and domain-specific data types where traditional codecs fall short. However, challenges remain, such as optimizing neural architectures, managing the tradeoffs between distortion and realism, and addressing the specific requirements of various data types. Despite these challenges, neural compression holds significant promise for revolutionizing data compression through its data-driven, adaptive methodologies [9].
D. Neural Compression in Satellite Images
In recent years, neural compression has been applied to satellite imagery and is starting to become a topic of interest, although there are still a limited number of studies on the subject. The most relevant is the one by Oliveira et al. [12] which proposes a reduced-complexity VAE tailored for on-board satellite image compression, addressing time and memory constraints while maintaining performance. This approach simplifies the entropy model by leveraging a statistical analysis that shows most features follow a Laplacian distribution, thus replacing complex nonparametric models with a simpler parametric estimation. The proposed model outperforms the Consultative Committee for Space Data Systems (CCSDS) standard and remains competitive with state-of-the-art learned compression schemes. Also, a few more have attempted to use neural compression in satellite images with promising results [31], [32]. Despite these advancements, the challenge of efficiently compressing and transmitting fast-increasing large volumes of satellite data remains. This study builds on the existing body of work by exploring the application of VAEs
and other advanced neural compression models for satellite image analysis, aiming to leverage the latent space directly for downstream machine learning tasks.
III. METHODOLOGY
A. Proposed Architecture
While neural compression techniques, such as those proposed in [10], [11], [27], [28], and [29], have significantly advanced the field of image compression, their primary focus has been on optimizing the compression and reconstruction stages. These methods, although effective in minimizing data loss during compression, typically require decompression before the data can be utilized for downstream tasks such as classification or segmentation. In our approach, we build upon these models and demonstrate that they can be adapted to function without the need for decompression. Specifically, we fine-tune these models to show that the latent spaces they generate can be directly exploited for downstream tasks. Our method thus diverges from the traditional workflow by utilizing the latent representations for classification tasks, thereby eliminating the need for reconstruction or inverse transformation and enhancing the overall efficiency of the process. In this study, we propose a novel architecture that integrates neural compression and classification within a unified framework. To illustrate the difference between the proposed architecture and conventional methods, Fig. 2 presents a typical pipeline for a traditional compression workflow. In this pipeline, the original image undergoes a transformation (e.g., DCT for JPEG or discrete wavelet transform for JPEG2000), followed by quantization and encoding through an entropy encoder. The entropy-coded data is then transmitted through a channel, decoded by an entropy decoder, and transformed back into the original image via an inverse DCT or a trained decoder, as in neural compression. Only after this final reconstruction step can the image be used for downstream tasks, such as classification. In contrast, as shown in Fig. 3, we propose that the lower dimensional transformation of the original image, produced by neural compression, can be directly used for downstream tasks such as classification, once entropy decoding has restored the data to a tensor format. Here, the neural network itself performs the transformation, generating a compact, lower dimensional “latent representation.” This representation is then
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


GIULIANO et al.: OPTIMIZING SATELLITE IMAGE ANALYSIS: VAEs LATENT REPRESENTATIONS 5603123
Fig. 3. Pipeline diagram for direct utilization of neural compressed images.
quantized, encoded using an entropy encoder, transmitted, and decoded by the entropy decoder on the other end of the transmission channel. Without the need for explicit reconstruction or inverse transformation, the learned latent space can be immediately leveraged for downstream tasks like classification, making the process more efficient. The proposed architecture comprises two key components: a neural compression model and a classification model. The neural compression model, built on advanced aforementioned VAE architectures, compresses high-dimensional satellite images into compact latent representations that preserve essential features for classification. The classification models are trained directly on these latent representations, effectively distinguishing between different classes of satellite images. We employ various classification models, each suited to different characteristics of the latent space: multilayer perceptrons (MLPs) were selected due to their straightforward architecture and basic feedforward neural network model, convolutional neural networks (CNNs) for spatial pattern recognition, and Transformers for handling complex dependencies. This diverse set of classifiers enables a comprehensive evaluation of our approach across multiple architectures. The full training process is detailed in Algorithm 1 below. To classify satellite images based on the latent spaces created by neural compression models, we employed the described architecture where we first trained six advanced VAE models for image compression: bmshj2018_factorized, bmshj2018_hyperprior, mbt2018_mean, mbt2018, cheng2020_anchor, and cheng2020_attn, from the CompressAI library (official port of Tensorflow neural compression library) [11], [27], [33]. The pretrained models weights were frozen at first to maintain the integrity of the learned latent spaces. Subsequently, we used these frozen models to generate latent representations of satellite images. These latent representations were then used as inputs to three different classification models: a CNN, an MLP, and a Transformer.
Mathematically, let x represent an input satellite image, and E(·) and D(·) denote the encoder and decoder of the compression models, respectively. The latent representation z is obtained as
z = E(x). (1)
For classification, we denote the classification model as C(z; θC ), where θC are the trainable parameters of the classification model. The output class probabilities yˆ are given by
yˆ = C(z; θC ). (2)
The training process involves minimizing a classification loss function Lclass (e.g., cross-entropy loss) between the predicted class probabilities yˆ and the true labels y
Lclass = −
X
i
yi log(yˆi ). (3)
B. Fine-Tuning
To further improve classification performance while maintaining low bit rates for reduced latency and transmission size, the models were fine-tuned to improve classification performance while retaining reconstruction capabilities and low bitrate. To do so, the fine-tuning loss function was a composite objective containing a term for each objective tempered by a multiplier, as shown in Algorithm 2. The reconstruction loss (Lrec) ensures that the VAE retains the ability to accurately reconstruct the original satellite images from the latent space. The classification loss (Lclass) drives the VAE to create latent representations that are useful for predicting the correct class labels. The bit rate loss (Lbpp) encourages the VAE to maintain an efficient compression, reducing the size of the latent representations. This composite loss is formulated using Lagrangian multipliers λrec, λclass, and λbpp to balance the tradeoffs between these objectives
Ltotal = λrecLrec + λclassLclass + λbppLbpp. (4)
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


5603123 IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 63, 2025
Algorithm 1 Training the Classifier on Latent Spaces Require: Pre-trained and frozen VAE model with encoder E and decoder D Require: Satellite image dataset {(xi , yi )}N
i =1
Require: Classification model: Classifier Ensure: Trained classification model: θC 1: Freeze weights of the VAE model 2: for each image xi in dataset do 3: Generate latent representation zi = E(xi ) 4: end for
5: Initialize classification model C with parameters θC 6: repeat
7: Sample a batch of latent representations {zb} and labels {yb} 8: Compute class probabilities yˆb = C(zb; θC ) 9: Compute classification loss Lclass 10: Update θC to minimize Lclass 11: until convergence 12: Save trained parameters θC
Algorithm 2 Fine-Tuning VAE and Training the Classifier on Latent Spaces Require: Pre-trained VAE model with encoder E and decoder D
Require: Satellite image dataset {(xi , yi )}N
i =1
Require: Classification model: Classifier Require: Weights for loss terms: λrec, λclass, λbpp Ensure: Fine-tuned VAE and trained classification model: θE , θD, θC
1: Initialize VAE model with parameters θE , θD 2: Initialize classification model C with parameters θC 3: repeat
4: Sample a batch of images {xb} and labels {yb} 5: Generate latent representations {zb} = E({xb}) 6: Reconstruct images {xˆb} = D({zb}) 7: Compute class probabilities yˆb = C({zb}; θC ) 8: Compute reconstruction loss Lrec = ∥xb − xˆb∥2 9: Compute classification loss Lclass =
−
P
i yb,i log(yˆb,i )
10: Compute bit rate loss Lbpp = R(zb)
11: Compute total loss Ltotal = λrecLrec + λclassLclass +
λbppLbpp
12: Update θE , θD, θC to minimize Ltotal 13: until convergence 14: Save fine-tuned parameters θE , θD and trained parameters θC where:
R(zb) =
log(latent).sum()
− log(2) · num_pixels
By incorporating a composite loss function that balances reconstruction accuracy, classification performance, and bit rate efficiency using Lagrangian multipliers, we ensure that the VAE is fine-tuned to produce latent spaces that are both efficient and highly discriminative, the change in latent
space composition is shown in Section V through t-distributed stochastic neighbor embedding (t-SNE) projections. This integrated training approach allows for a more comprehensive optimization, where the VAE and classifier are jointly trained to maximize overall performance. As a result, the latent spaces generated by the fine-tuned VAE are optimized for multiple objectives, making them particularly effective for classification tasks while still benefiting from the compactness and efficiency of the VAE-based compression. This approach to temper composite loss functions has been seen, for example, in Beta-VAEs. By incorporating the Beta-VAE, the latent spaces generated are not only compact and efficient but also disentangled, which is particularly beneficial for classification tasks. The β parameter in the Beta-VAE acts similar to a Lagrangian multiplier, balancing the tradeoff between reconstruction fidelity and latent space regularization [34].
C. Latent Space Visualization
To visualize and compare the latent spaces generated by the VAE, we utilized t-SNE. t-SNE is a powerful dimensionality reduction technique that is particularly well-suited for visualizing high-dimensional data in a lower dimensional space, typically two or three dimensions. It is similar to stochastic neighborhood embedding but works better on high-dimensional data composed of several low-dimensional manifolds such as the ones produced by VAE for multiclass images [35]. t-SNE operates by converting the similarities between data points in the high-dimensional space into joint probabilities and then tries to optimize the low-dimensional representation to preserve these similarities. This is achieved through a probabilistic approach where a Gaussian distribution represents the similarity between two points in the high-dimensional space, while in the low-dimensional space, it is represented by a student’s t-distribution with one degree of freedom (a Cauchy distribution). This choice of distribution in the low-dimensional space helps to manage the so-called “crowding problem,” where too many points are mapped too closely together. Mathematically, t-SNE works as follows. For each pair of points (i, j), t-SNE calculates the conditional probability p j|i that point j would be chosen as a neighbor of point i if neighbors were picked in proportion to their probability density under a Gaussian centered at i
p j|i =
exp −∥xi − x j ∥2/2σ 2
i
P
k̸=i exp −∥xi − xk ∥2/2σ 2
i
(5)
where xi and x j are the high-dimensional input data points, and σi is the variance of the Gaussian centered at xi . The joint probability pi j is then symmetrized
pi j =
p j|i + pi| j
2N (6)
where N is the number of data points. In the low-dimensional space, a similar joint probability qi j is computed using a student’s t-distribution
qi j =
(1 + ∥yi − y j ∥2)−1
P
k̸=l (1 + ∥yk − yl ∥2)−1 (7)
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


GIULIANO et al.: OPTIMIZING SATELLITE IMAGE ANALYSIS: VAEs LATENT REPRESENTATIONS 5603123
Fig. 4. Sample t-SNE manifold of the testing set of the EuroSAT dataset encoded using a VAE with a scale hyperprior, image patches from Sentinel-2 mission.
where yi and y j are the low-dimensional representations of the data points. t-SNE aims to minimize the Kullback–Leibler (KL) divergence between the high-dimensional and low-dimensional joint probabilities
KL(P∥Q) =
X
i̸= j
pi j log pi j
qi j
. (8)
This is typically done using gradient descent, where the positions of the points in the low-dimensional space are iteratively adjusted to minimize the KL divergence. t-SNE is particularly suitable for our application because it effectively captures the local structure of the data, making it easier to identify clusters and patterns within the latent space. By visualizing the latent spaces using t-SNE, we can gain insights into how well the VAE has learned to represent the data and how distinct the latent representations are for different classes. This visualization helps in evaluating the quality of the latent space and the effectiveness of the VAE model in capturing essential features of the satellite images. In our study, t-SNE was used to project the high-dimensional latent representations into a 2-D space using perplexity = 30, and 500 iterations, where each point represents a data sample’s latent vector. The resulting 2-D plot provides a visual comparison of the latent spaces, highlighting the clustering of data points based on their class labels, as shown in Fig. 4.
D. Rate-Distortion Accuracy Index (RDAI)
To compare the efficacy of fine-tuning and assess the results of various neural compression and classification models on both reconstruction quality and classification performance, we introduce the RDAI inspired by the works of Luo et al. [36] on the rate-distortion accuracy tradeoff in JPEG. This novel metric integrates the critical aspects of rate, distortion, and accuracy, providing a comprehensive evaluation framework for neural compression methods. The RDAI is defined as a weighted combination of rate, distortion, and accuracy. Given that BPP will be between 0 and 10, peak signal-to-noise ratio (PSNR) between 0 and 60, and F1 between 0 and 1,
Fig. 5. Models compression performance comparison performed on EuroSAT test set.
we normalize PSNR to the range [0, 1] as follows:
PSNRnormalized =
PSNR
60 . (9)
The formula for RDAI is then given by
RDAI = α ·
10 − BPP
10 + β ·
PSNR
60 + γ · F1 (10)
where α, β, and γ are the weights assigned to each component, such that α + β + γ = 1. During this study, we gave all three components equal weight and importance, and therefore α = β
= γ = (1/3). PSNR measuring the distortion. Higher PSNR values indicate better preservation of image quality based on the mean squared error of all pixels
PSNR = 10 · log10
MAX2
MSE
!
(11)
where MAX is the maximum possible pixel value of the image (e.g., 255 for an 8-bit image), and MSE is the mean squared error between the original and compressed image. In our case, we use MAX = 1 since the images are transformed to float32 tensors during preprocessing. F1 is the F1 score of the neural network on the compressed images, used as our accuracy metric. Higher F1 scores indicate better classification performance
F1 = 2 ·
precision · recall
precision + recall . (12)
The F1 score is preferred over accuracy for evaluating the performance of a neural network on compressed images due to its robustness in handling imbalanced classes. Accuracy measures the proportion of correct predictions out of all predictions, which can be misleading when class distribution is imbalanced. The F1 score, being the harmonic mean of precision and recall, balances false positives and false negatives, providing a more comprehensive assessment of the model’s performance.
IV. EXPERIMENTAL SETUP
A. Hardware
All of the experiments were carried out with PyTorch and CUDA cores using GPU NVIDIA GeForce RTX 4070 Ti
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


5603123 IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 63, 2025
Super (16 Gb), CPU Intel1 Core2 i7-14700KF, 3400 MHz, 20 Core(s), 28 Logical Processor(s), and RAM DDR5 128 GB at 6000 MHz. Tensorboard was used to log all results including time series, scalar, and image data.
B. Neural Compression Models Used
In this study, we employ a variety of advanced VAE architectures and their derivatives to achieve efficient image compression and examine the utilization of the constructed latent space. The models examined include bmshj2018_factorized, bmshj2018_hyperprior, mbt2018_mean, mbt2018, cheng2020_anchor, and cheng2020_attn extensively pretrained to compress images. Each of these models leverages different techniques to encode images into compact latent representations while preserving essential information for accurate reconstruction and downstream tasks. The bmshj2018_factorized model employs a fully factorized density model for latent variables. Each latent variable yi is assumed to be independent and identically distributed (i.i.d.), such that
p(y) =
Y
i
p(yi ). (13)
This model uses a nonparametric piecewise linear density to approximate each factor of the prior. The density p is defined using its cumulative distribution function (cdf) c, where
p(x) =
∂c(x)
∂ x . (14)
By ensuring that the cumulative function c is monotonic and maps R to [0, 1], a valid density function can be constructed as
c = fK ◦ fK −1 ◦ · · · ◦ f1 (15)
with
p = f′
K · f′
K −1 · · · · · f ′
1
where fk are vector functions composed of matrices H (k), biases b(k), and element-wise nonlinearities gk defined as
gk(x) = x + a(k) ⊙ tanh(x) (16)
where a(k) are vectors controlling the expansion or contraction rate. The bmshj2018_hyperprior model introduces a hyperprior to capture spatial dependencies among the elements of the latent representation y. This is achieved by an auxiliary autoencoder which models the latent scales using another set of latent variables z, defined as
z = ha(y; φh) (17)
and
p(y|z) = N (y; 0, σ 2(z; θh)). (18)
1Registered trademark. 2Trademarked.
Here, ha and hs denote the analysis and synthesis transforms in the auxiliary autoencoder. The hyperprior model enhances the entropy model by conditioning on z, leading to more accurate and spatially adaptive entropy estimates. The mbt2018_mean model extends the bmshj2018_hyperprior by incorporating a mean prediction in addition to the scale prediction for the Gaussian distribution of the latent variables
p(y|z) = N (y; μ(z; θh), σ 2(z; θh)). (19)
This allows the model to capture the mean shift in the latent space, providing a more flexible and accurate entropy model by predicting both mean μ and scale σ from the hyperprior. The mbt2018 model combines the hyperprior with an autoregressive context model to further refine the entropy estimation. The context model uses previously decoded latents to improve the prediction of the current latent
p(yi |y<i , z) = N (yi ; μ(y<i , z), σ 2(y<i , z)). (20)
This joint model leverages both the spatial dependencies captured by the hyperprior and the sequential dependencies captured by the autoregressive model, leading to a significant improvement in compression performance. The cheng2020_anchor model introduces discretized Gaussian mixture likelihoods to model the distributions of latent codes more flexibly. This is formulated as
p(y|z) =
K
X
k=1
w(k)N (y; μ(k)(z), σ 2(k)(z)). (21)
This mixture model is designed to capture complex distributions of latent variables by using multiple Gaussian components, each with its own mean and scale parameters conditioned on the hyperprior. This approach reduces spatial redundancy and improves the accuracy of entropy models, achieving better compression performance. Finally, the cheng2020_attn model incorporates attention mechanisms to improve the performance of the image compression model. The attention modules help the network focus on complex regions of the image, enhancing the rate-distortion performance. The attention mechanism is integrated into the network architecture as
y = f (x; θ, A) (22)
where A represents the attention module parameters. The attention module modifies the convolutional features to prioritize information-rich regions, leading to better compression results. It is important to note that each of the models was evaluated at three distinct quality levels. These levels represent directly the magnitude of the Lagrangian multiplier and channel size of the latent representation itself, which increases from 192 to 320 for the former and from 128 to 192 for the latter and are used to weight the compression versus distortion performance of the models. The levels go from 1 to 8 for bmshj2018_factorized, bmshj2018_hyperprior, mbt2018_mean, mbt2018 and 1–6 for cheng2020_anchor, and cheng2020_attn. The former were evaluated at 2, 5, and
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


GIULIANO et al.: OPTIMIZING SATELLITE IMAGE ANALYSIS: VAEs LATENT REPRESENTATIONS 5603123
TABLE I
NUMBER OF PARAMETERS IN VARIOUS NEURAL COMPRESSION MODELS
8 while the latter at 2, 4, and 6. A comparison of the size of each neural compression model at different quality levels can be seen in Table I. All networks were pretrained for 45M steps on 256 × 256 image patches randomly extracted and cropped from the Vimeo90K dataset [37]. In Section V, the results are presented for each model underscoring the quality level of the pretrained models.
C. Classification Models Used
In this study, we utilized three different types of classification models: an MLP, a CNN, and a Transformer. Each model was specifically designed to leverage the latent spaces generated by the pretrained and fine-tuned VAE for classifying satellite images. 1) Multilayer Perceptron: The MLP model consists of three fully connected layers. The input dimension is determined by the size of the latent space produced by the VAE. The architecture of the MLP can be represented as follows:
Layer 1: h1 = σ (W1z + b1)
Layer 2: h2 = σ (W2h1 + b2)
Output Layer: yˆ = W3h2 + b3
where z is the input latent representation, Wi and bi are the weights and biases of layer i, σ is the activation function [rectified linear unit (ReLU)], and yˆ is the output class probabilities.
2) Convolutional Neural Network: The CNN model is designed to handle the spatial dimensions of the latent representations. In this case, we use a custom residual connection (ResNet) architecture, which is adjusted to accommodate the specific input dimensions and number of output classes. The architecture can be summarized as follows:
Convolution: h1 = σ (conv1(z))
Residual Blocks: h2 = ResNet blocks(h1)
Pooling: h3 = global average pooling(h2)
Output Layer: yˆ = fully connected(h3) (23)
where z is the input latent representation, conv1 is the first convolutional layer tailored to the dimension of the relative
TABLE II
NUMBER OF PARAMETERS IN VARIOUS CLASSIFICATION MODELS
latent space, σ is the activation function (ReLU), and the ResNet blocks represent the sequence of residual blocks in the ResNet architecture. The global average pooling and fully connected layer produce the final output class probabilities yˆ. 3) Transformer: The Transformer model incorporates positional encoding and a multilayer transformer encoder. This model is well-suited for capturing long-range dependencies in the latent space. The architecture includes an input projection layer, positional encoding, and a transformer encoder followed by a fully connected layer. The process can be described as follows:
Input Projection: h0 = proj(z)
Positional Encoding: h1 = h0 + pos_enc(h0)
Transformer Encoding: h2 = transformer_encoder(h1)
Global Average Pooling: h3 = mean(h2, dim = 1)
Output Layer: ˆy = Wh3 + b
where z is the input latent representation, proj denotes the input projection, pos_enc is the positional encoding, transformer_encoder represents the transformer encoder layers, mean denotes global average pooling, and yˆ is the output class probabilities. These models were selected for their distinct architectures and capabilities in handling different aspects of the latent representations generated by the VAE. The MLP is straightforward and efficient for general-purpose classification, the CNN leverages spatial information, and the Transformer is adept at capturing complex dependencies within the data. Pretrained models for image classification, such as those trained on large-scale datasets like ImageNet, were not suitable for our application. The latent representations generated by the VAE are inherently different from raw image data, as they are a compressed and abstract representation of the original images. Consequently, using pretrained models directly on these latent spaces would not effectively capture the specific features encoded by the VAE. Therefore, we opted to design and train custom classification models tailored to the latent space characteristics. The dimensions, in terms of parameters, for each classification model can be seen in Table II.
D. Dataset
Three different datasets were used to test the proposed architecture: EuroSAT [38], RSI-CB256 [39], and PatternNet [40]. The EuroSAT dataset consists of Sentinel-2 satellite images
covering 13 spectral bands, with 27 000 labeled images divided Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


5603123 IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 63, 2025
TABLE III
EVALUATING PRETRAINED CLASSIFIERS PERFORMANCE ON MULTIPLE JPEG COMPRESSION QUALITY LEVELS ON EUROSAT DATASET; MLP, CNN WITH RESNETS, AND VIT
Fig. 6. Reconstruction F1 and BPP versus JPEG quality levels.
into ten classes: annual crop, forest, herbaceous vegetation, highway, industrial, pasture, permanent crop, residential, river, and sea/lake. Each image has a spatial resolution of 10 m per pixel and is provided in 64 × 64 pixel patches. EuroSAT is a well-regarded benchmark for satellite image classification tasks due to its diverse range of land cover classes and highquality imagery. In addition to the EuroSAT dataset, we utilized the RSICB-256 dataset, which consists of 24 000 images spanning 35 land-use classes, each with a resolution of 256 × 256 pixels and a spatial resolution of 0.3 m. This dataset covers a diverse range of land-use categories, including woodlands (e.g., forest, sapling, and shrubwood) and transportation scenes (e.g., crossroads, highways, marinas, and river bridges), making it a valuable resource for evaluating the differentiation of various land-use types. The comprehensive labeling, large size, and varied environmental conditions make it an excellent choice for evaluating the performance of our VAE-based image compression and classification approach. We also integrated the PatternNet dataset, another wellregarded dataset, comprising 30 400 images across 38 classes that represent various urban and suburban environments, such as airports, harbors, and stadiums. Each image in PatternNet has a resolution of 256 × 256 pixels and captures intricate patterns characteristic of human-made structures, collected from Google Earth. The inclusion of PatternNet enables us to
Fig. 7. Reconstruction PSNR and BPP versus JPEG quality levels.
assess the model’s robustness in identifying and distinguishing complex, highly structured man-made environments. To ensure compatibility with our model, the original image patches from the EuroSAT dataset were preprocessed and resized to 256 × 256 pixels using bilinear interpolation, preserving the integrity of the images while adapting them to the required dimensions. For all datasets, we restricted our usage to the RGB bands to ensure compatibility with standard image processing pipelines. Although we explored normalization techniques to standardize the datasets, normalization proved ineffective in enhancing model performance and was therefore not utilized. The images were used in their raw form without any normalization, ensuring that the intrinsic characteristics of the data were maintained. We also explored normalization techniques to standardize the dataset during the preprocessing phase. However, normalization proved to be ineffective in enhancing model performance, likely due to the reduction in variance of the dataset, and was therefore not utilized. The images were used in their raw form without any normalization, ensuring that the intrinsic characteristics of the data were maintained. To maintain conciseness, the results presented in Section V of the article are based exclusively on the EuroSAT dataset. Corresponding results for the other two datasets are provided in Appendixes A and B.
V. RESULTS
A. Baseline
To establish a baseline comparison between the proposed architecture and standard compression models, we tested JPEG compression at various quality levels. We compared these models not only in terms of compression capabilities but also in terms of classification accuracy using pretrained classifiers similar to the custom ones built for our experiments. We applied JPEG compression to the Sentinel-2 images at various quality levels (e.g., 10%, 30%, 50%, 70%, and 90%) to assess the impact of compression on image quality and size, especially in terms of loss of information and accuracy at lower levels. As shown in Fig. 5 each method’s performance demonstrates how image quality, as measured by PSNR, improves with an increase in BPP. The JPEG method (pink)
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


GIULIANO et al.: OPTIMIZING SATELLITE IMAGE ANALYSIS: VAEs LATENT REPRESENTATIONS 5603123
Fig. 8. t-SNE visualizations of models constructed latents of EuroSAT test set, with labels. (a) bmshj2018_hyperprior 2. (b) bmshj2018_hyperprior 5. (c) bmshj2018_hyperprior 8. (d) bmshj2018_factorized 2. (e) bmshj2018_factorized 5. (f) bmshj2018_factorized 8. (g) mbt2018 2. (h) mbt2018 5. (i) mbt2018 8. (j) mbt2018_mean 2. (k) mbt2018_mean 5. (l) mbt2018_mean 8. (m) cheng2020_anchor 2. (n) cheng2020_anchor 4. (o) cheng2020_anchor 6. (p) cheng2020_attn 2. (q) cheng2020_attn 4. (r) cheng2020_attn 6.
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


5603123 IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 63, 2025
TABLE IV
PERFORMANCE COMPARISON OF MLP, CNN, AND TRANSFORMER MODELS, USING ALGORITHM 1 AND FROZEN WEIGHTS FOR NEURAL COMPRESSION MODELS. ACCURACY AND F 1 REPRESENT CLASSIFICATION RESULTS OF MODELS USING NEURAL COMPRESSED LATENT REPRESENTATIONS
Fig. 9. Effects of tuning the λbpp multiplier on RDAI (left axis) and BPP (right axis) values.
shows a consistent but less efficient performance compared to neural methods, especially at higher BPP values, indicating poorer compression efficiency. In contrast, methods like bmshj2018_hyperprior (blue) and mbt2018_mean (green) exhibit significantly higher PSNR values at equivalent BPPs, showcasing their superior ability to retain image quality at lower bit rates as expected. As JPEG reconstruction quality levels increases, the F1 scores for all classifiers generally improve, indicating better classification performance with higher image quality, as shown in Fig. 6 as well as better reconstruction quality as shown in Fig. 7. The ResNet classifier shows the most significant improvement, achieving an F1 score above 0.95 at higher
JPEG quality levels. The vision transformer (ViT) classifier also demonstrates strong performance, with F1 scores approaching 0.9. The MLP classifier, while improving with higher quality levels, shows a more modest increase in F1 scores compared to the other two classifiers, probably due to the simplicity of its architecture. The average BPP increases significantly with higher JPEG quality levels, reflecting the tradeoff between compression efficiency and image quality. The equally weighted RDAI metric peaks at quality level 70 for both ResNet and ViT, indicating an optimal tradeoff between compression, reconstruction quality, and classification accuracy at this level as shown in Table III.
B. Frozen Weights
To assess the performance of the neural compression models in creating meaningful latent spaces that are utilizable from other machine learning models, we used quantitative and qualitative metrics. Quantitatively, metrics such as F1 score, PSNR, BPP, and RDAI were employed to measure the classification performance, reconstruction quality, compression efficiency, and the tradeoffs between these factors, respectively. These metrics provide a comprehensive evaluation of how well the neural compression models balance the competing requirements of high compression rates and high classification accuracy. Qualitatively, t-SNE visualizations were used to assess the structure of the latent spaces generated by the neural compression models. The t-SNE plots, as shown in Fig. 8, illustrate how different models organize the latent representations of the EuroSAT test set. These visualizations highlight the clustering
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


GIULIANO et al.: OPTIMIZING SATELLITE IMAGE ANALYSIS: VAEs LATENT REPRESENTATIONS 5603123
Fig. 10. t-SNE visualizations of fine-tuned models constructed latents of EuroSAT test set, with labels. (a) bmshj2018_hyperprior 2. (b) bmshj2018_hyperprior 5. (c) bmshj2018_hyperprior 8. (d) bmshj2018_factorized 2. (e) bmshj2018_factorized 4. (f) bmshj2018_factorized 8. (g) mbt2018 2. (h) mbt2018 5. (i) mbt2018 8. (j) mbt2018_mean 2. (k) mbt2018_mean 5. (l) mbt2018_mean 8. (m) cheng2020_anchor 2. (n) cheng2020_anchor 4. (o) cheng2020_anchor 6. (p) cheng2020_attn 2. (q) cheng2020_attn 4. (r) cheng2020_attn 6.
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


5603123 IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 63, 2025
TABLE V
FINE-TUNING PERFORMANCE USING VARIOUS METHODS AND TRANSFORMER CLASSIFIER
Fig. 11. Fine-tuning performance in terms of RDAI versus BPP for bmshj2018_hyperprior [2, 5, 8] with no bit rate loss constraint (red), with no reconstruction loss constraint (blue), with no reconstruction, and bit rate loss constraint (green).
and separability of the latent features, which are crucial for downstream classification tasks. We performed a first round of experiments using the logic explained previously in Algorithm 1. The pretrained neural compression models’ parameters were frozen and then used to compress images from the EuroSAT train dataset. The latent spaces created were used to train three separate classifiers (MLP, CNN, and Transformer), results can be seen in Table IV. When comparing the performance with JPEG compression at quality level 100, which serves as a high-quality baseline, it is evident that neural compression models significantly enhance classification performance while maintaining lower BPP values. For instance, the MLP classifier using bmshj2018_hyperprior_8 achieves an F1 score of 0.6856 and a PSNR of 49.14 with a BPP of 0.3459, substantially better than the JPEG’s F1 score of 0.4606 and PSNR of 42.85, and at a fraction of the BPP for a similar classifier. Similarly, the ResNet50 classifier with bmshj2018_hyperprior_8 shows an F1 score of 0.5011 and a PSNR of 49.14 at a BPP of 0.3389, surpassing the JPEG’s performance. The Transformer
classifier exhibits the highest performance gains, with the bmshj2018_hyperprior_8 configuration achieving an F1 score of 0.794, a PSNR of 49.14, and an RDAI of 0.8608, all at a BPP of 0.2816. This trend is consistent across other neural compression models; for instance, mbt2018_mean_8 and mbt2018_8 configurations show significant improvements in F1 scores and PSNR values while maintaining lower BPP compared to JPEG. These results highlight the superiority of neural compression techniques in balancing compression efficiency and classification accuracy. From these results, we can also extrapolate that by interpreting directly the latent spaces some of the information that would be lost during decompression is preserved. In addition, the RDAI metric, which provides a comprehensive measure of the tradeoffs between rate, distortion, and accuracy, consistently shows higher values for neural compression models across all classifiers, further validating their effectiveness over traditional JPEG compression. In particular, the Transformer classifier, when paired with bmshj2018_hyperprior_8, achieves an RDAI of 0.8608, indicating an optimal balance and best performance for both neural compression and JPEG values. The t-SNE plots in Fig. 8 illustrate how different models, such as cheng2020_anchor, mbt2018_mean, bmshj2018_hyperprior, bmshj2018_factorized, and cheng2020_attn, organize the latent representations of the EuroSAT test set. For example, the bmshj2018_hyperprior models show better-defined clusters at higher bitrates, indicating that the latent space captures meaningful structures even at lower compression rates. The bmshj2018_hyperprior and cheng2020_attn models, particularly at higher bitrates, demonstrate clear separations between clusters, suggesting that these models retain significant feature information necessary for high classification. It also shows that there is a direct correlation between better separation in the latent space and higher classification accuracy, which makes sense. The visualizations also reveal that models like bmshj2018_factorized_8, while achieving high PSNR and F1 scores, might have more overlapping clusters, which could impact classification performance in more challenging scenarios.
C. Fine-Tuning
The second set of experiments was carried out following the logic outlined in Algorithm 2 for fine-tuning the VAE along with the training of the classifiers. To test this, we selected the best-performing classifier from the previous experiments (the Transformer architecture) and trained it jointly using the composite loss shown in (4). This composite loss function was designed to optimize both the reconstruction quality and classification performance simultaneously, allowing the VAE to adapt its latent space to better suit the classification task. To temper and balance the various elements of the composite loss function, the Lagrangian multipliers were fine-tuned using a grid search on various models, which resulted in the best values to be λrec = 10, λclass = 1, and λbpp = 0.075. The grid search spanned values between [0.01, 1, 10] for all multipliers. It was then narrowed down using halfway points [0.05, 0.075] to further improve performance. Choosing the right multiplier parameters turned out to be crucial to improving the overall
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


GIULIANO et al.: OPTIMIZING SATELLITE IMAGE ANALYSIS: VAEs LATENT REPRESENTATIONS 5603123
TABLE VI
PERFORMANCE COMPARISON USING FROZEN WEIGHTS FOR NEURAL COMPRESSION MODELS APPLIED TO THE PATTERNNET DATASET
TABLE VII
PERFORMANCE OF PRETRAINED CLASSIFIERS ON DIFFERENT JPEG COMPRESSION LEVELS APPLIED TO THE PATTERNNET DATASET
performance of the models. An example of the effects of choosing the λbpp parameter can be seen in Fig. 9. Choosing a λbpp that is too low results in a high bitrate as not enough importance is assigned to compression during the multiobjective optimization process. While if λbpp is too large, then the data is compressed excessively, and information is lost in the process lowering the reconstruction and classification performance, ultimately hurting RDAI scores. When comparing the performance of the fine-tuned combinations of neural compression models and transformer classifier we see a substantial increase in performance. The fine-tuned Transformer model consistently outperformed the frozen weight counterpart and the JPEG baseline. We can see in Table V that the fine-tuned cheng2020_attn_6 achieves and RDAI of 0.890, the highest of all experiments and a substantial increase from the performance using pretrained frozen weights with an RDAI of 0.83. When comparing this result with the
TABLE VIII
FINE-TUNING PERFORMANCE USING VARIOUS METHODS AND TRANSFORMER CLASSIFIER APPLIED TO THE PATTERNNET DATASET
JPEG baseline we can see a better reconstruction performance of 44.94 at a bit rate of 0.2615 where JPEG is only able to achieve 32.14 and much better classification performance with an F1 score of 94.87 versus JPEG ViT F1 score of 66.47. Therefore, the lossy neural compression model is able to achieve better performance at lower bitrates in both classification and reconstruction. If we compare the performance of the various neural compression models qualitatively on top of quantitatively we can see from Fig. 10 that the best performing neural compression models learn to induce separation in the latent spaces between classes, effectively clustering similar images together. This proves particularly
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


5603123 IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 63, 2025
Fig. 12. t-SNE visualizations of models constructed latents of PatternNet test set, with labels. (a) bmshj2018_hyperprior 2. (b) bmshj2018_hyperprior 5. (c) bmshj2018_hyperprior 8. (d) bmshj2018_factorized 2. (e) bmshj2018_factorized 4. (f) bmshj2018_factorized 8. (g) mbt2018 2. (h) mbt2018 5. (i) mbt2018 8. (j) mbt2018_mean 2. (k) mbt2018_mean 5. (l) mbt2018_mean 8. (m) cheng2020_anchor 2. (n) cheng2020_anchor 4. (o) cheng2020_anchor 6. (p) cheng2020_attn 2. (q) cheng2020_attn 4. (r) cheng2020_attn 6.
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


GIULIANO et al.: OPTIMIZING SATELLITE IMAGE ANALYSIS: VAEs LATENT REPRESENTATIONS 5603123
Fig. 13. t-SNE visualizations of models constructed latents of PatternNet test set, with labels. (a) bmshj2018_hyperprior 2. (b) bmshj2018_hyperprior 5. (c) bmshj2018_hyperprior 8. (d) bmshj2018_factorized 2. (e) bmshj2018_factorized 4. (f) bmshj2018_factorized 8. (g) mbt2018 2. (h) mbt2018 5. (i) mbt2018 8. (j) mbt2018_mean 2. (k) mbt2018_mean 5. (l) mbt2018_mean 8. (m) cheng2020_anchor 2. (n) cheng2020_anchor 4. (o) cheng2020_anchor 6. (p) cheng2020_attn 2. (q) cheng2020_attn 4. (r) cheng2020_attn 6.
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


5603123 IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 63, 2025
Fig. 14. t-SNE visualizations of models constructed latents of RSICB-256 test set, with labels. (a) bmshj2018_hyperprior 2. (b) bmshj2018_hyperprior 5. (c) bmshj2018_hyperprior 8. (d) bmshj2018_factorized 2. (e) bmshj2018_factorized 4. (f) bmshj2018_factorized 8. (g) mbt2018 2. (h) mbt2018 5. (i) mbt2018 8. (j) mbt2018_mean 2. (k) mbt2018_mean 5. (l) mbt2018_mean 8. (m) cheng2020_anchor 2. (n) cheng2020_anchor 4. (o) cheng2020_anchor 6. (p) cheng2020_attn 2. (q) cheng2020_attn 4. (r) cheng2020_attn 6.
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


GIULIANO et al.: OPTIMIZING SATELLITE IMAGE ANALYSIS: VAEs LATENT REPRESENTATIONS 5603123
Fig. 15. t-SNE visualizations of models constructed latents of RSICB-256 test set, with labels. (a) bmshj2018_hyperprior 2. (b) bmshj2018_hyperprior 5. (c) bmshj2018_hyperprior 8. (d) bmshj2018_factorized 2. (e) bmshj2018_factorized 4. (f) bmshj2018_factorized 8. (g) mbt2018 2. (h) mbt2018 5. (i) mbt2018 8. (j) mbt2018_mean 2. (k) mbt2018_mean 5. (l) mbt2018_mean 8. (m) cheng2020_anchor 2. (n) cheng2020_anchor 4. (o) cheng2020_anchor 6. (p) cheng2020_attn 2. (q) cheng2020_attn 4. (r) cheng2020_attn 6.
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


5603123 IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 63, 2025
TABLE IX
PERFORMANCE OF PRETRAINED CLASSIFIERS ON DIFFERENT JPEG COMPRESSION LEVELS. THE TABLE SHOWS THE VALUES OF AVERAGE BPP, PSNR, F 1, AND RDAI FOR MLP, RESNET, AND VIT CLASSIFIERS APPLIED TO THE RSI-CB256 DATASET
beneficial for classification with the cheng2020_attn models performing best and showing the greatest separation between clusters, while the bmshj2018_factorized performs the worse and shows a lot more overlapping between clusters and poor separation.
D. Ablation Study
During parameter selection for the Lagrange multipliers through grid search, various scenarios were explored, including the absence of some components from the composite objective function to study the effects. The aim was to understand how each component influenced the overall performance of the model. For instance, by omitting certain terms, we could observe changes in the model’s ability to balance different objectives, such as compression efficiency and reconstruction quality. Since the neural compression models were pretrained, there was no point in experimenting with λclass being zero. This would have simply meant trying to fine-tune the neural compression model to the dataset, which would have reduced generalizability and generally shown to reduce performance. Instead, we focused on testing three specific scenarios that allowed us to investigate the tradeoffs between different components of the objective function. These scenarios are illustrated in Fig. 11 and are detailed below. 1) No Constraint on Bit-Rate:
λclass = 1, λbpp = 0, λrec = 10.
2) No Constraint on Bit-Rate and Reconstruction:
λclass = 1, λbpp = 0, λrec = 0.
3) No Constraint on Reconstruction:
λclass = 1, λbpp = 1, λrec = 0.
As seen in Fig. 11, both scenarios that cancel out the “bpp” term and do not optimize for bitrate result in poor compression performance, with bitrates all higher than 3 BPP. The “No Constraint on Bit-Rate and Reconstruction” scenario performs the worst, achieving low reconstruction and compression performance. In addition, it does not significantly increase classification performance, remaining comparable to the better-performing fine-tuned models shown earlier. The
“No Constraint on Reconstruction” scenario results in lower bitrates and similar classification performance, but very poor reconstruction performance as expected. Therefore, while it could be a viable solution if the only goal is known classification, it might not be possible to reconstruct the original image.
VI. DISCUSSION
The findings from this study demonstrate the potential of using neural compression models, specifically VAEs, to enhance satellite image analysis by leveraging latent representations directly for classification tasks. This approach offers a significant improvement over traditional methods, in terms of the compression, reconstruction, and accuracy tradeoff. The results highlight several key aspects. First, in terms of compression efficiency and reconstruction quality, neural compression models, such as bmshj2018 hyperprior and cheng2020 attn, achieve higher compression ratios while maintaining excellent reconstruction quality. The PSNR values for these models are significantly higher than those obtained with JPEG compression, even at lower bit rates, indicating better preservation of image quality. This improvement is crucial for applications where both storage and transmission efficiency are paramount, such as remote sensing and environmental monitoring. The higher compression efficiency means that more data can be stored and transmitted without significant loss of quality, making it feasible to handle the large volumes of data generated by satellite imagery. Moreover, the latent representations generated by these neural compression models are highly effective for classification tasks, in future studies the utilization of such latent spaces for other tasks such as segmentation and object detection will be explored. The Transformer classifier, when fine-tuned with these latent spaces, achieves remarkable F1 scores, demonstrating that the latent spaces retain essential features for accurate classification as well as the viability of using the proposed architecture. This performance indicates that neural compression models do not just compress the data but also preserve critical information necessary for downstream tasks. By using the latent spaces directly, the approach eliminates the need for decompression, reducing computational overhead and loss of information. The visualizations of latent spaces using t-SNE further support these findings, showing well-defined clusters corresponding to different classes, particularly for models like cheng2020 attn. This clear separability in the latent space is crucial for high classification performance, as it indicates that the model has effectively learned to distinguish between different types of images. The t-SNE plots illustrate that the best-performing models induce a structured and meaningful organization in the latent space, which is directly correlated with their classification performance. This proves that neural compression models can successfully be fine-tuned for specific tasks without sacrificing reconstruction quality and compression ratios.
A. Limitations and Future Work
While our study demonstrates the potential of VAE models with Gaussian and discretized Gaussian mixture likelihoods
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


GIULIANO et al.: OPTIMIZING SATELLITE IMAGE ANALYSIS: VAEs LATENT REPRESENTATIONS 5603123
TABLE X
PERFORMANCE COMPARISON USING FROZEN WEIGHTS FOR NEURAL COMPRESSION MODELS APPLIED TO THE RSI-CB256 DATASET
TABLE XI
FINE-TUNING PERFORMANCE USING VARIOUS METHODS AND TRANSFORMER CLASSIFIER APPLIED TO THE RSI-CB256 DATASET
for neural compression and classification tasks, it does not include more recent neural compression models due to several limitations that must be acknowledged. A key constraint is our reliance on pretrained models available through the CompressAI library. These models were trained using specific and undisclosed configurations, techniques, and hyperparameters, such as the application of an exponential moving average for weight updates and the implementation of a gradually decaying learning rate schedule, both of which are commonly used in VAE training to mitigate instability. The lack of transparency and control over the pretraining process introduces challenges in maintaining consistency across models. Attempting to incorporate more recent methods, such as
hierarchical VAEs or diffusion models, without consistent pretraining conditions could lead to biased comparisons and potentially compromise the validity of our results. Moreover, integrating these other advanced models would have required a significant shift in the focus of the study. Hierarchical VAEs [28], diffusion models [29], and other hybrid architectures [30] represent distinct classes of neural compression techniques that would necessitate different experimental setups, comparisons, and analyses. This article is specifically focused on exploring the capabilities of Gaussian-based VAE models for classification tasks. Including these more recent models would extend the scope of the article beyond the primary objective and would require a different research approach to thoroughly evaluate and compare the diverse set of models. Therefore, while these advanced models offer promising avenues for future research, they were intentionally excluded from this work to maintain clarity and focus in addressing our specific research goals. Future work should focus on experimenting with new neural compression architectures, such as hierarchical VAEs and diffusion models, as well as expanding the scope to other tasks beyond classification, including segmentation and object detection.
B. Security Considerations
In addition to the benefits of compression efficiency and classification performance, the use of neural compression models for satellite image analysis also offers notable security advantages. The process of transforming satellite images into latent representations inherently applies a form of data masking. This transformation makes it significantly more difficult for unauthorized parties to reconstruct the original images without access to the specific neural compression model used
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


5603123 IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 63, 2025
for encoding and decoding. This added layer of security is particularly important for sensitive applications, such as military or confidential environmental monitoring, where the protection of raw data is paramount. By transmitting only the latent representations instead of the raw images, we reduce the risk of data interception and misuse during transmission. Furthermore, the neural compression models can be designed to incorporate additional security measures, such as encryption of the latent space, further enhancing data protection. This approach can be integrated seamlessly into existing data processing pipelines, ensuring that security does not come at the expense of efficiency or accuracy. The robustness of these neural compression models against potential attacks aimed at extracting sensitive information from the latent space is an area worthy of further research. Investigating the resilience of different neural architectures and training methodologies to adversarial attacks will be crucial in ensuring the security and reliability of these systems in practical applications. Overall, leveraging neural compression models for satellite image analysis not only optimizes data handling but also provides an enhanced security framework, addressing one of the critical concerns in the transmission and storage of satellite imagery.
VII. CONCLUSION
This study demonstrates the effectiveness of neural compression models for satellite image analysis within the proposed architecture. By utilizing the latent spaces generated by these models, we achieve significant improvements in both compression efficiency and classification accuracy, with additional benefits for data transmission and analysis. The compact latent representations not only enable efficient storage and transmission but also enhance the speed and accuracy of downstream tasks, while providing a degree of data security by obfuscating the original images. Future research could build on this work by integrating neural compression models with other machine learning frameworks, potentially expanding their applicability and improving performance across a broader range of scenarios. Further advancements in the architecture could optimize compression and classification tasks beyond current limitations. In addition, applying these latent spaces to tasks such as segmentation, object detection, and anomaly detection would help generalize and validate this approach across diverse remote sensing applications, offering new insights and capabilities for satellite image analysis. Furthermore, expanding the use of these compressed representations in multimodal learning scenarios, combining satellite imagery with other data sources like sensor data or textual information, could significantly enhance the ability to extract meaningful patterns across complex datasets. Embracing these advancements could revolutionize the way we process and analyze satellite imagery in the future.
APPENDIX A
PATTERNNET DATASET RESULTS
See Tables VI–VIII and Figs. 12 and 13.
APPENDIX B
RSI-CB256 DATASET RESULTS
See Tables IX–XI and Figs. 14 and 15.
REFERENCES
[1] L. Ma, Y. Liu, X. Zhang, Y. Ye, G. Yin, and B. A. Johnson, “Deep learning in remote sensing applications: A metaanalysis and review,” ISPRS J. Photogramm. Remote Sens., vol. 152, pp. 166–177, Jun. 2019. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/S0924271619301108 [2] Y. Liu, X. Chen, Z. Wang, Z. J. Wang, R. K. Ward, and X. Wang, “Deep learning for pixel-level image fusion: Recent advances and future prospects,” Inf. Fusion, vol. 42, pp. 158–173, Jul. 2018. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/S1566253517305936 [3] L. H. Hughes, M. Schmitt, L. Mou, Y. Wang, and X. X. Zhu, “Identifying corresponding patches in SAR and optical images with a pseudoSiamese CNN,” IEEE Geosci. Remote Sens. Lett., vol. 15, no. 5, pp. 784–788, May 2018. [Online]. Available: http://ieeexplore.ieee. org/document/8314449/ [4] G. Cheng, C. Yang, X. Yao, L. Guo, and J. Han, “When deep learning meets metric learning: Remote sensing image scene classification via learning discriminative CNNs,” IEEE Trans. Geosci. Remote Sens., vol. 56, no. 5, pp. 2811–2821, May 2018. [Online]. Available: http://ieeexplore.ieee.org/document/8252784/ [5] Z. Deng, H. Sun, S. Zhou, J. Zhao, L. Lei, and H. Zou, “Multiscale object detection in remote sensing imagery with convolutional neural networks,” ISPRS J. Photogramm. Remote Sens., vol. 145, pp. 3–22, Nov. 2018. [Online]. Available: https://linkinghub.elsevier. com/retrieve/pii/S0924271618301096 [6] X.-Y. Tong et al., “Land-cover classification with high-resolution remote sensing images using transferable deep models,” Remote Sens. Environ., vol. 237, Feb. 2020, Art. no. 111322. [7] R. Kemker, C. Salvaggio, and C. Kanan, “Algorithms for semantic segmentation of multispectral remote sensing imagery using deep learning,” ISPRS J. Photogramm. Remote Sens., vol. 145, pp. 60–77, Nov. 2018. [Online]. Available: https://linkinghub.elsevier. com/retrieve/pii/S0924271618301229 [8] L. Ma, M. Li, X. Ma, L. Cheng, P. Du, and Y. Liu, “A review of supervised object-based land-cover image classification,” ISPRS J. Photogrammetry Remote Sens., vol. 130, pp. 277–293, Aug. 2017, [Online]. Available: https://linkinghub.elsevier. com/retrieve/pii/S092427161630661X [9] Y. Yang, S. Mandt, and L. Theis, “An introduction to neural data compression,” 2022, arXiv:2202.06533. [10] J. Ballé, V. Laparra, and E. P. Simoncelli, “End-to-end optimized image compression,” 2016, arXiv:1611.01704. [11] Z. Cheng, H. Sun, M. Takeuchi, and J. Katto, “Learned image compression with discretized Gaussian mixture likelihoods and attention modules,” 2020, arXiv:2001.01568.
[12] V. A. de Oliveira et al., “Reduced-complexity end-to-end variational autoencoder for on board satellite image compression,” Remote Sens., vol. 13, no. 3, p. 447, Jan. 2021. [Online]. Available: https://www.mdpi.com/2072-4292/13/3/447 [13] C. Li et al., “CasFormer: Cascaded transformers for fusionaware computational hyperspectral imaging,” Inf. Fusion, vol. 108, Aug. 2024, Art. no. 102408. [Online]. Available: https://linkinghub. elsevier.com/retrieve/pii/S1566253524001866 [14] C. Li, B. Zhang, D. Hong, X. Jia, A. Plaza, and J. Chanussot, “Learning disentangled priors for hyperspectral anomaly detection: A coupling model-driven and data-driven paradigm,” IEEE Trans. Neural Netw. Learn. Syst., pp. 1–14, 2024. [Online]. Available: https://ieeexplore. ieee.org/document/10547283/ [15] C. Li et al., “Interpretable networks for hyperspectral anomaly detection: A deep unfolding solution,” IEEE Trans. Geosci. Remote Sens., vol. 62, 2024, Art. no. 5536414, doi: 10.1109/TGRS.2024.3434382. [Online]. Available: https://ieeexplore.ieee.org/document/10613787/ [16] D. Hong et al., “Cross-city matters: A multimodal remote sensing benchmark dataset for cross-city semantic segmentation using high-resolution domain adaptation networks,” Remote Sens. Environ., vol. 299, Dec. 2023, Art. no. 113856. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/S0034425723004078
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.


GIULIANO et al.: OPTIMIZING SATELLITE IMAGE ANALYSIS: VAEs LATENT REPRESENTATIONS 5603123
[17] D. Hong et al., “SpectralGPT: Spectral remote sensing foundation model,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 46, no. 8, pp. 5227–5244, Aug. 2024. [Online]. Available: https://ieeexplore. ieee.org/document/10490262/ [18] A. H. Robinson and C. Cherry, “Results of a prototype television bandwidth compression scheme,” Proc. IEEE, vol. 55, no. 3, pp. 356–364, Mar. 1967. [Online]. Available: http://ieeexplore. ieee.org/document/1447423/ [19] D. Huffman, “A method for the construction of minimum-redundancy codes,” Proc. IRE, vol. 40, no. 9, pp. 1098–1101, Sep. 1952. [Online]. Available: http://ieeexplore.ieee.org/document/4051119/ [20] T. Welch, “A technique for high-performance data compression,” IEEE Comput., vol. C-17, no. 6, pp. 8–19, Jul. 1984. [Online]. Available: http://ieeexplore.ieee.org/document/1659158/ [21] X. Yu, J. Zhao, T. Zhu, Q. Lan, L. Gao, and L. Fan, “Analysis of JPEG2000 compression quality of optical satellite images,” in Proc. 2nd Asia–Pacific Conf. Commun. Technol. Comput. Sci. (ACCTCS), Shenyang, China, Feb. 2022, pp. 500–503. [Online]. Available: https://ieeexplore.ieee.org/document/9820991/ [22] S.-E. Qian, M. Bergeron, I. Cunningham, L. Gagnon, and A. Hollinger, “Near lossless data compression onboard a hyperspectral satellite,” IEEE Trans. Aerosp. Electron. Syst., vol. 42, no. 3, pp. 851–866, Jul. 2006. [Online]. Available: http://ieeexplore.ieee.org/document/4014456/ [23] V. Sanchez, F. Aulí-Llinàs, and J. Serra-Sagristà, “DPCM-based edge prediction for lossless screen content coding in HEVC,” IEEE J. Emerg. Sel. Topics Circuits Syst., vol. 6, no. 4, pp. 497–507, Dec. 2016. [Online]. Available: http://ieeexplore.ieee.org/document/7579210/ [24] F. Mentzer, E. Agustsson, J. Ballé, D. Minnen, N. Johnston, and G. Toderici, “Neural video compression using GANs for detail synthesis and propagation,” 2021, arXiv:2107.12038. [25] L. Helminger, A. Djelouah, M. Gross, and C. Schroers, “Lossy image compression with normalizing flows,” 2020, arXiv:2008.10486. [26] C.-W. Huang, D. Krueger, A. Lacoste, and A. Courville, “Neural autoregressive flows,” in Proc. 35th Int. Conf. Mach. Learn., vol. 80, J. Dy and A. Krause, Eds., Stockholmsmässan, Sweden, Jul. 2018, pp. 2078–2087. [27] J. Ballé, D. Minnen, S. Singh, S. J. Hwang, and N. Johnston, “Variational image compression with a scale hyperprior,” 2018, arXiv:1802.01436. [28] Z. Duan, M. Lu, Z. Ma, and F. Zhu, “Lossy image compression with quantized hierarchical VAEs,” in Proc. IEEE/CVF Winter Conf. Appl. Comput. Vis. (WACV), Jan. 2023, pp. 198–207. [29] J. Liu, H. Sun, and J. Katto, “Learned image compression with mixed transformer-CNN architectures,” in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2023, pp. 14388–14397. [Online]. Available: https://ieeexplore.ieee.org/document/10204195/ [30] R. Yang and S. Mandt, “Lossy image compression with conditional diffusion models,” in Proc. Adv. Neural Inf. Process. Syst., vol. 36, A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, Eds. Curran Associates, Inc., 2023, pp. 64971–64995. [Online]. Available: https://proceedings.neurips.cc/paper_files/paper/2023/file/ccf6d8b4a1fe9 d9c8192f00c713872ea-Paper-Conference.pdf [31] P. Bacchus, R. Fraisse, A. Roumy, and C. Guillemot, “Quasi lossless satellite image compression,” in Proc. IEEE Int. Geosci. Remote Sens. Symp., Kuala Lumpur, Malaysia, Jul. 2022, pp. 1532–1535. [Online]. Available: https://ieeexplore.ieee.org/document/9883135/ [32] G. Guerrisi, F. Del Frate, and G. Schiavon, “Convolutional autoencoder algorithm for on-board image compression,” in Proc. IEEE Int. Geosci. Remote Sens. Symp., Kuala Lumpur, Malaysia, Jul. 2022, pp. 151–154. [Online]. Available: https://ieeexplore.ieee.org/document/9883256/ [33] D. Minnen, J. Ballé, and G. Toderici, “Joint autoregressive and hierarchical priors for learned image compression,” 2018, arXiv:1809.02736. [34] I. Higgins et al., “β-VAE: Learning basic visual concepts with a constrained variational framework,” in Proc. ICLR, 2017. [35] L. van der Maaten and G. Hinton, “Visualizing data using t-SNE,” J. Mach. Learn. Res., vol. 9, pp. 2579–2605, Nov. 2008. [Online]. Available: http://jmlr.org/papers/v9/vandermaaten08a.html [36] X. Luo, H. Talebi, F. Yang, M. Elad, and P. Milanfar, “The ratedistortion-accuracy tradeoff: JPEG case study,” 2020, arXiv:2008.00605. [37] T. Xue, B. Chen, J. Wu, D. Wei, and W. T. Freeman, “Video enhancement with task-oriented flow,” Int. J. Comput. Vis., vol. 127, no. 8, pp. 1106–1125, Feb. 2019, doi: 10.1007/s11263-018-01144-2. [38] P. Helber, B. Bischke, A. Dengel, and D. Borth, “EuroSAT: A novel dataset and deep learning benchmark for land use and land cover classification,” IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., vol. 12, no. 7, pp. 2217–2226, Jul. 2019. [Online]. Available: https://ieeexplore.ieee.org/document/8736785/
[39] H. Li et al., “RSI-CB: A large-scale remote sensing image classification benchmark using crowdsourced data,” Sensors, vol. 20, no. 6, p. 1594, Mar. 2020. [40] W. Zhou, S. Newsam, C. Li, and Z. Shao, “PatternNet: A benchmark dataset for performance evaluation of remote sensing image retrieval,” ISPRS J. Photogramm. Remote Sens., vol. 145, pp. 197–209, Nov. 2018. [Online]. Available: https://linkinghub.elsevier. com/retrieve/pii/S0924271618300042
Alessandro Giuliano (Graduate Student Member, IEEE) received the Bachelor of Engineering degree in mechanical engineering from the University of Guelph, Guelph, ON, Canada, in 2021. He is currently pursuing the Ph.D. degree with the Department of Mechanical Engineering, McMaster University, Hamilton, ON, Canada. He has authored or co-authored more than 16 papers in multiple conferences, including one Winning Best Paper Award from IEEE IEMTRONICS 2022. His research interests include IoT systems, remote sensing, machine learning, multimodal data fusion, and satellite imagery analysis.
S. Andrew Gadsden (Senior Member, IEEE) received the B.Eng. degree in mechanical engineering and management (business) and the Ph.D. degree in mechanical engineering in the area of estimation theory from McMaster University, Hamilton, ON, Canada, in 2006 and 2011, respectively. He is currently an Associate Professor and the Associate Chair (Graduate Studies) with the Department of Mechanical Engineering, McMaster University, and was previously an Associate Professor at the University of Guelph, Guelph, ON, Canada, and an Assistant Professor at the University of Maryland, College Park, MD, USA. Dr. Gadsden was a recipient of numerous international awards and recognitions. Most notably, he and his fellow air-LUSI project teammates were awarded NASA’s prestigious 2021 Robert H. Goddard Award in Science for their work on developing an airborne lunar spectral irradiance instrument. He also received the 2019/2020 University Research Excellence Award for the College of Engineering and Physical Sciences based on his research activities at the University of Guelph. He is also a 2019 SPIE Rising Researcher Award Winner based on his work in intelligent estimation theory and a 2018 Ontario Early Researcher Award (ERA) Winner based on his work in intelligent condition monitoring strategies. He was also awarded the 2019 University of Guelph Faculty Association (UGFA) Distinguished Professor Award for Excellence in Teaching at the College of Engineering and Physical Sciences based on his teaching effectiveness and pedagogy. Finally, he and his team have received three Best Paper Awards based on research publications.
John Yawney received the Ph.D. degree in applied mathematics from the University of Waterloo, Waterloo, ON, Canada, in 2016. He is currently the Chief Analytics Officer with Adastra Corporation, Toronto, ON, Canada. He has Executive Oversight of the Data Science Practice, leads the development of the AI solutions portfolio, and holds an Adjunct Professor status with the Department of Mechanical Engineering, McMaster University, Hamilton, ON, Canada. The advancement of the analytics space at Adastra Corporation and its global offices relies on his expertise and his development of practical but theoretically sound solutions and AI service frameworks, for which he leverages his joint academic and industry focus. He has extensive experience with building production AI/ML systems and performing numerical and statistical analyses. His research portfolio/focus includes numerical simulations of nonlinear systems, epidemiological modeling, applied AI applications, and cognitive systems.
Authorized licensed use limited to: McMaster University. Downloaded on February 27,2025 at 17:02:46 UTC from IEEE Xplore. Restrictions apply.